{
  "hash": "d09140f9eaadc9057b4727c2de95ffa6",
  "result": {
    "markdown": "# AI - GSE105777\n\n## Packages to use\n\nFirst load the packages that will be used along the cleaning\nprocess. Always do this at the beginning of your script to make\nthings organized. \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GEOquery)\nlibrary(SummarizedExperiment)\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(janitor)\n\nlibrary(readxl)\n\nlibrary(ggplot2)\n```\n:::\n\n## Introduction\n\nWe will download and process the aromatase inhibitor data available\nat GEO under accession code: GSE105777. The data is associated\nto the paper \nhttps://breast-cancer-research.biomedcentral.com/articles/10.1186/s13058-019-1223-z. \n\nKi67 levels are also available to these patients in the supplementary data.\nWe will also download the data available there and combine it here.\n\n## Downloading data\n\nTo download the data use the package GEOquery from Bioconductor and\nspecify the accession code. Save also the data on a directory of your \nchoice. In this case I chose a subfolder called data in my current directory.\n\n::: {.cell}\n\n```{.r .cell-code}\ngse_ai <- GEOquery::getGEO(\n    \"GSE105777\", \n    destdir = \"./data\", \n    GSEMatrix = TRUE\n)[[1]]\n```\n:::\n\nThe function `exprs` from the package Biobase (automatically loaded if\nyou have bioconductor) let us check the expression levels of the\nexpression set downloaded with GEOquery.\n\n::: {.cell}\n\n```{.r .cell-code}\nexprs(gse_ai)\n```\n:::\n\nAnd since this is a microarray experiment we need information to \nmap the probe ids to the genes. This information is stored in the\nfeature slot of the expression set above. To retrieve it use\nthe function `fData`.\n\n::: {.cell}\n\n```{.r .cell-code}\nfData(gse_ai)\n```\n:::\n\nAnd now load the ki67 levels data from the supplementary material. Remember\nto specify the folder where your file is located. The table is pivoted\nfor the ki67 levels, such that each patient will have two rows, one for baseline\nand another for surgery.\n\n::: {.cell}\n\n```{.r .cell-code}\nki67_levels <- readxl::read_excel(\n    path = \"data/13058_2019_1223_MOESM2_ESM.xlsx\",\n    range = \"TableS4!A3:L257\", \n) %>% janitor::clean_names() %>% \n    tidyr::pivot_longer(\n        cols = c(\"baseline_ki67\", \"surgery_ki67\"), \n        names_to = \"timepoint\",\n        values_to = \"ki67\"\n    ) %>% \n    dplyr::mutate(ki67 = as.numeric(ki67)) %>%\n    dplyr::mutate(\n        title = ifelse(\n            group == \"Peri AI\",\n            paste0(\n                \"AI.\", \n                number_254_tumours_control_56_ai_treated_198,\n                ifelse(timepoint == \"baseline_ki67\", \"B\", \"S\")\n            ),\n            paste0(\n                number_254_tumours_control_56_ai_treated_198,\n                ifelse(timepoint == \"baseline_ki67\", \"B\", \"S\")\n            )\n        )\n    )\n\nki67_levels %>% head\n```\n:::\n\n## Cleaning and integrating\n\nWe start now integrating the clinical data available from the GEOquery \nwith the ki67 levels data. \n\n::: {.cell}\n\n```{.r .cell-code}\n# first convert the title of control samples (reanalysis) to the same\n# format as the treated patients. this will make it easier down the line\n# to match samples\ncol_data <- pData(gse_ai) %>%\n    dplyr::mutate(\n        title = ifelse(\n            !stringr::str_detect(title, \"reanalysis\"), \n            title,\n            paste0(\n                \"Control.\", \n                as.integer(stringr::str_extract(title, \"\\\\d+\")),\n                ifelse(`sampling time:ch1` == \"diagnosis\", \"B\", \"S\")\n            )\n        )\n    )\n\ncol_data$title %>% tail\n```\n:::\n\nWe now add both together. The function `inner_join` from the dplyr\npackage is very powerful. Remember to always specify by which column you want\nto merge. It is usually very fast to merge tables this way, since it handles\nthe matching of the columns for you. \n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_col_data <- dplyr::inner_join(\n    ki67_levels,\n    col_data %>% tibble::rownames_to_column(var = \"gsm_name\"),\n    by = \"title\"\n)\n```\n:::\n\nTo check the total number of patients, use the code below. \n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_col_data$patient_id %>% table %>% length\n```\n:::\n \nThe number of controls are:\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_col_data %>% dplyr::filter(\n    group == \"No Peri AI\"\n) %>% janitor::tabyl(number) %>% nrow\n```\n:::\n\nAnd the number of treated patients are:\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_col_data %>% dplyr::filter(\n    group == \"Peri AI\"\n) %>% janitor::tabyl(number) %>% nrow\n```\n:::\n\nAnd since we have multiple illumina IDs mapping to the same gene,\nwe take their average. \n\n::: {.cell}\n\n```{.r .cell-code}\n# we first start removing the duplicated genes, but\n# we will change the average expression levels later\ngse_ai <- gse_ai[-which(is.na(exprs(gse_ai)), arr.ind = TRUE)[, 1], ]\n```\n:::\n\nBelow we calculate the average intensity for probe ids with multiple\nhugo symbols. \n\n::: {.cell}\n\n```{.r .cell-code}\n# first get the duplicated symbols\nduplicated_symbols <- fData(gse_ai) %>%\n    janitor::tabyl(ILMN_Gene) %>%\n    dplyr::filter(n > 1)\n\n# and check what are the probe ids available in the data\nduplicated_ilmns <- fData(gse_ai) %>% dplyr::filter(\n    ILMN_Gene %in% duplicated_symbols$ILMN_Gene\n)\n\n# here we use sapply to calculate the average median intensity\n# for each hugo symbol. this approach is faster than using a for loop.\n# whenever you can i suggest to use sapply in R instead of a for loop.\nmean_intensity <- sapply(\n    duplicated_symbols$ILMN_Gene,\n    function(symbol, gse_ai, fdata){\n        \n        ilmn_ids <- fdata %>% dplyr::filter(\n            ILMN_Gene == symbol\n        ) %>% dplyr::pull(ID)\n        \n        colMeans(exprs(gse_ai)[ilmn_ids, ], na.rm = TRUE)\n        \n    },\n    gse_ai = gse_ai,\n    fdata = fData(gse_ai)\n)\n```\n:::\n\nWe now remove from the expression matrix the duplicated genes and\nthen add their mean values.\n\n::: {.cell}\n\n```{.r .cell-code}\nexprs_vals <- exprs(gse_ai)[-which(rownames(gse_ai) %in% duplicated_ilmns$ID), ]\n\n# first change the name of the current illumina ids \nrownames(exprs_vals) <- fData(gse_ai)[rownames(exprs_vals), \"ILMN_Gene\"]\n\n# now we add the average values\nexprs_vals <- rbind(\n    exprs_vals,\n    t(data.frame(mean_intensity))\n)\n```\n:::\n\nAnd before saving the final object, we clean the clinical data available\nto us so it is easier to work with. Below we show all the columns available to \nsee which columns will be dropped.\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_col_data %>% colnames\n```\n:::\n\nAfter inspecting, the columns that will be dropped are shown below.\n\n::: {.cell}\n\n```{.r .cell-code}\ncolumns_to_drop <- c(\n    \"geo_accession\", \"status\", \"submission_date\", \"last_update_date\", \n    \"type\", \"channel_count\", \"source_name_ch1\", \"organism_ch1\",\n    \"molecule_ch1\", \"extract_protocol_ch1\", \"label_ch1\", \"label_protocol_ch1\",\n    \"taxid_ch1\", \"hyb_protocol\", \"scan_protocol\", \"data_processing\",\n    \"platform_id\", \"contact_name\", \"contact_email\", \"contact_laboratory\",\n    \"contact_department\", \"contact_institute\", \"contact_address\", \"contact_city\",\n    \"contact_state\", \"contact_zip/postal_code\", \"contact_country\",\n    \"supplementary_file\", \"data_row_count\", \"relation\",\n    \"Sex:ch1\", \"tissue:ch1\", \"characteristics_ch1\",\n    \"characteristics_ch1.1\", \"characteristics_ch1.2\", \"characteristics_ch1.4\",\n    \"characteristics_ch1.5\", \"her2:ch1\", \"timepoint:ch1\", \"sampling time:ch1\",\n    \"group\", \"paired_or_baseline_single\", # all samples are paired in this case \n    \"number_254_tumours_control_56_ai_treated_198\", \"characteristics_ch1.3\",\n    \"disease:ch1\", \"subtype:ch1\", \"description\", \"title\"\n)\n\nfinal_col_data_drop <- final_col_data %>% \n    dplyr::mutate(pam50 = as.character(`subtype:ch1`)) %>%\n    dplyr::select(-dplyr::one_of(columns_to_drop)) %>% \n    dplyr::mutate(\n        timepoint = stringr::str_replace_all(timepoint, \"_ki67\", \"\"),\n        r_or_no_r_change_ki67_60_and_baseline_ki67_5_percent = ifelse(\n            is.na(r_or_no_r_change_ki67_60_and_baseline_ki67_5_percent),\n            \"not_available\",\n            ifelse(\n                r_or_no_r_change_ki67_60_and_baseline_ki67_5_percent == \"non-responder\",\n                \"non_responder\",\n                r_or_no_r_change_ki67_60_and_baseline_ki67_5_percent\n            )\n        ),\n        ccca_surgery_ki67_2_7 = ifelse(\n            is.na(ccca_surgery_ki67_2_7),\n            \"not_available\",\n            ccca_surgery_ki67_2_7\n        ),\n        pam50 = tolower(pam50)\n    ) %>% \n    dplyr::mutate(\n        pam50 = ifelse(is.na(pam50), \"not_available\", pam50),\n        number = as.character(number),\n        name_patient = paste(`group:ch1`, paste0(\"nb\", number), timepoint, sep = \"_\")\n    ) %>% \n    dplyr::rename(\n        group = `group:ch1`,\n        patient_nb = number\n    ) %>% data.frame %>% \n    `rownames<-`(.$name_patient)\n```\n:::\n\nGlimpse is a function to show some entries of all your columns in a nice way.\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::glimpse(final_col_data_drop)\n```\n:::\n\nAfter cleaning the clinical data, we can merge with the expression data\nand save using a summarized experiment object. We just make\nsure the columns are in the right order first. \n\n::: {.cell}\n\n```{.r .cell-code}\nmatch_names <- match(colnames(exprs_vals), final_col_data_drop$gsm_name)\ncolnames(exprs_vals) <- final_col_data_drop[\n    match_names,\n    \"name_patient\"\n]\n```\n:::\n\nAnd we use an object from the package SummarizedExperiment to store\nthe data. The idea is similar to an ExpressionSet, but the functions\nto access the data are a bit diffrent. Instead of using `exprs`, one\nnow uses `assay` and to get the clinical data one uses `colData` instead\nof using `pData`. There is no feature data in this case. \n\n::: {.cell}\n\n```{.r .cell-code}\ngse_ai <- SummarizedExperiment::SummarizedExperiment(\n    assays = list(\n        normalized_intensity = exprs_vals\n    ),\n    colData = final_col_data_drop[colnames(exprs_vals), ]\n)\n```\n:::\n\nI highly suggest to save this object in an rds object, so\nyou do the cleaning process just once and data is ready\nto use afterwards.\n\n::: {.cell}\n\n```{.r .cell-code}\nsaveRDS(gse_ai, \"data/gse_ai.rds\")\n```\n:::\n\nAnd to reload the data into R the `readRDS` function can be used.\n\n::: {.cell}\n\n```{.r .cell-code}\ngse_ai <- readRDS(\"data/gse_ai.rds\")\n```\n:::",
    "supporting": [
      "ai_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}